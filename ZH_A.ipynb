{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bevezetés az adattudományba - gyakorlati zárthelyi dolgozat\n",
    "\n",
    "A zárthelyi során a Autók árait (Price) kell majd megprediktálni. A zárthelyi dolgozatot a kiadott notebook-ban kell megoldani és ebben a formában kell visszatölteni. A fájl nevét módosítsd a következőre: GipszJakab_ABC123. A zárthelyi megoldására 60 perc áll rendelkezésre.   \n",
    "\n",
    "## Feladatok:\n",
    "1. Adatbeolvasás:  \n",
    "1.1 Olvasd be az adatot egy dataframe-be, és jelenítsed meg az első 5 sorát. 1p   \n",
    "1.2 3-4 mondatban írd le az adathalmazt, milyen oszlopaink vannak és miket jelenthetnek. 4p    \n",
    "  \n",
    "2. Adat műveletek:   \n",
    "2.1 Töröld az következő oszlopokat: ColourExtInt, CylindersinEngine, Title 1p \n",
    "2.2 Nézde meg hogy oszloponként hány hiányzó adat van a dataframe-ben. 1p  \n",
    "2.3 A Location oszlop hiányzó adatait töltsed fel \"Unknown\" értékkel. 1p   \n",
    "2.4 Töröld azokat a sorokat ahol bármelyik adat hiányzik. 1p  \n",
    "2.5 Néhány mondatban írd le, hogy a törlésen kívül milyen más módszereket lehet használni a hiányzó adatok kezelésére.  2p  \n",
    "2.6 Készíts egy új oszlopot Age néven. A Year oszlop segítségével számold ki az autók korát. (2023-ból vond ki az értékeket) 2p.    \n",
    "2.7 Töröld a Year oszlopot. 1p.\n",
    "  \n",
    "3. Adat vizualizáció:  \n",
    "3.1 Jelenítsd meg, hány darab autó van az egyes Age kategóriákban . Az X tengelyen szerepeljen az Age, Y tengelyen pedig az autók mennyisége. 3p   \n",
    "3.2 Jelenítsd meg egy kör diagramon, hogy milyen arányban vannak használt és új autók az adatok között. Használd a UsedOrNew oszlopot. A diagramhoz készíts magyarázatot, melyik szelet melyik és szerepeljen rajta a százalék is. 3p  \n",
    "\n",
    "4. Modell tanítás:  \n",
    "4.1 Konvertáld szám értékekké azon oszlopok érétkeit ahol jelenleg szöveges adat van. 1p   \n",
    "4.2 Készíts egy X és egy y változót. X-ben szerepeljenek az autókhoz tartózó feature-ok, y-ban pedig a hozzájuk tartozó ár. 1p   \n",
    "4.3 Bontsd fel az adathalmazt tanító és teszt részhalmazra. Az adatok 80%-a legyen tanító adat, 20%-a pedig teszt. 1p  \n",
    "4.4 Taníts fel egy random forest-et. Használd hozzá a következő import-ot: 'from sklearn.ensemble import RandomForestRegressor' 1p  \n",
    "4.5 A RF kívül még milyen más modelt lehetett volna használni? Hogyan kellett volna módosítani az adathalmazunkat? 2p  \n",
    " \n",
    "5. Értékelés:  \n",
    "5.1 Értékeld a modelled teljesítményét és pontosságát. 2p    \n",
    "5.2 Milyen lépéseket lehetne még megtenni a jobb pontosság elérése érdekében? 3p\n",
    "\n",
    "6. Extra feladat:   \n",
    "6.1 Random keresés segítségével próbálj meg javítani az elért pontosságon. Jelenítsed meg melyek lettek a legjobb parméterek és mennyivel jobb eredményt sikerült ezekkel elérni.\n",
    "\n",
    "SUM: 30p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. feladat\n",
    "### 1.1 feladat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data into a dataframe\n",
    "df = pd.read_csv('path/to/your/data.csv')\n",
    "\n",
    "# Display the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 feladat:\n",
    "[VÁLASZ HELYE]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. feladat\n",
    "### 2.1 feladat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Töröld az következő oszlopokat: ColourExtInt, CylindersinEngine, Title 1p\n",
    "df.drop(['ColourExtInt', 'CylindersinEngine', 'Title'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 feladat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Nézde meg hogy oszloponként hány hiányzó adat van a dataframe-ben. 1p\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 feladat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 A Location oszlop hiányzó adatait töltsed fel \"Unknown\" értékkel. 1p\n",
    "df['Location'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 feladat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 Töröld azokat a sorokat ahol bármelyik adat hiányzik. 1p\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 feladat:\n",
    "[VÁLASZ HELYE]\n",
    "# # 2.5 Néhány mondatban írd le, hogy a törlésen kívül milyen más módszereket lehet használni a hiányzó adatok kezelésére.  2p\n",
    "A hiányzó adatok kezelésére a törlésen kívül több más módszer is alkalmazható:\n",
    "\n",
    "1. Imputáció: A hiányzó értékeket becsült értékekkel helyettesíthetjük a rendelkezésre álló adatok alapján. Ezt különböző technikákkal végezhetjük, például átlag imputációval, medián imputációval, mód imputációval vagy regressziós imputációval.\n",
    "\n",
    "2. Előre vagy hátra kitöltés: A hiányzó értékeket kitölthetjük a korábbi vagy következő megfigyelt értékkel a datasetben. Ez a módszer hasznos idősoros adatok vagy olyan esetekben, amikor a hiányzó értékek várhatóan hasonlóak a közeli értékekhez.\n",
    "\n",
    "3. Hot Deck imputáció: A hiányzó értékeket hasonló rekordokban található értékekkel helyettesíthetjük. Ez a módszer magában foglalja a hasonló jellemzőkkel rendelkező rekordok megtalálását és az értékeik használatát a hiányzó értékek kitöltésére.\n",
    "\n",
    "4. Többszörös imputáció: Ez a módszer több imputált adatkészlet létrehozását jelenti, ahol a hiányzó értékeket észszerű értékekkel töltjük ki az észlelt adatok alapján. Statisztikai elemzést végeznek minden imputált adatkészleten, majd az eredményeket kombinálják a végső becslés megszerzéséhez.\n",
    "\n",
    "5. Gépi tanulási algoritmusok: A hiányzó értékeket külön kategóriaként kezelhetjük, vagy olyan gépi tanulási algoritmusokat használhatunk, amelyek közvetlenül kezelik a hiányzó értékeket, például döntési fák vagy random forestek.\n",
    "\n",
    "Fontos a megfelelő módszer kiválasztása az adatok jellegétől és az elemzés konkrét követelményeitől függően."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 feladat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# 2.6 Készíts egy új oszlopot Age néven. A Year oszlop segítségével számold ki az autók korát. (2023-ból vond ki az értékeket) 2p.\n",
    "current_year = datetime.datetime.now().year\n",
    "df['Age'] = current_year - df['Year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 feladat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.7 Töröld a Year oszlopot. 1p.\n",
    "df.drop('Year', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. feladat\n",
    "### 3.1 feladat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Jelenítsd meg, hány darab autó van az egyes Age kategóriákban.\n",
    "# Az X tengelyen szerepeljen az Age, Y tengelyen pedig az autók mennyisége. 3p\n",
    "df['Age'].value_counts().plot(kind='bar')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Number of Cars')\n",
    "plt.title('Number of Cars in Each Age Category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 feladat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Jelenítsd meg egy kör diagramon, hogy milyen arányban vannak használt és új autók az adatok között.\n",
    "# Használd a UsedOrNew oszlopot. A diagramhoz készíts magyarázatot, melyik szelet melyik és szerepeljen rajta a százalék is. 3p\n",
    "df['UsedOrNew'].value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
    "plt.legend()\n",
    "plt.title('Proportion of Used and New Cars')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. feladat\n",
    "### 4.1 feladat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Konvertáld szám értékekké azon oszlopok érétkeit ahol jelenleg szöveges adat van. 1p\n",
    "columns_to_convert = ['column1', 'column2', 'column3']  # Replace with the actual column names\n",
    "df[columns_to_convert] = df[columns_to_convert].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 feladat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Készíts egy X és egy y változót. X-ben szerepeljenek az autókhoz tartózó feature-ok, y-ban pedig a hozzájuk tartozó ár. 1p\n",
    "X = df.drop('Price', axis=1)\n",
    "y = df['Price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 feladat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Bontsd fel az adathalmazt tanító és teszt részhalmazra.\n",
    "# Az adatok 80%-a legyen tanító adat, 20%-a pedig teszt. 1p\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and test subsets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 feladat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4 Taníts fel egy random forest-et. Használd hozzá a következő import-ot: 'from sklearn.ensemble import RandomForestRegressor' 1p\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create a random forest regressor object\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 feladat\n",
    "[VÁLASZ HELYE]\n",
    "# 4.5 A RF kívül még milyen más modelt lehetett volna használni? Hogyan kellett volna módosítani az adathalmazunkat? 2p  \n",
    "\n",
    "To answer the question, there are several other models that could have been used instead of Random Forest (RF). Some alternative models include:\n",
    "\n",
    "1. Linear Regression: This model assumes a linear relationship between the features and the target variable. To use linear regression, you would need to convert any categorical variables into numerical ones using techniques like one-hot encoding.\n",
    "\n",
    "2. Support Vector Machines (SVM): SVM is a powerful model for both classification and regression tasks. It works by finding the best hyperplane that separates the data points into different classes. To use SVM, you would need to scale the features to have similar ranges.\n",
    "\n",
    "3. Gradient Boosting: Gradient boosting is an ensemble method that combines multiple weak learners (decision trees) to create a strong predictive model. It works by iteratively adding new trees that correct the mistakes made by previous trees. To use gradient boosting, you would need to convert any categorical variables into numerical ones using techniques like label encoding.\n",
    "\n",
    "4. Neural Networks: Neural networks are a powerful class of models that can learn complex patterns in the data. They consist of multiple layers of interconnected nodes (neurons) that perform mathematical operations on the input data. To use neural networks, you would need to scale the features to have similar ranges and potentially one-hot encode categorical variables.\n",
    "\n",
    "To modify the dataset for these models, you may need to perform additional preprocessing steps such as handling missing values, scaling the features, and encoding categorical variables. Each model has its own requirements and assumptions, so it's important to carefully consider the specific needs of the chosen model when modifying the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. feladat\n",
    "### 5.1 feladat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Értékeld a modelled teljesítményét és pontosságát. 2p\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Calculate the R2 score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 feladat\n",
    "[VÁLASZ HELYE]\n",
    "\n",
    "# 5.2 Milyen lépéseket lehetne még megtenni a jobb pontosság elérése érdekében? 3p\n",
    "A jobb pontosság elérése érdekében számos lépést lehetne még tenni. Néhány javasolt lépés:\n",
    "\n",
    "1. Adatok tisztítása: Ellenőrizd az adatokat, hogy nincsenek-e hiányzó vagy hibás értékek. Ha vannak, akkor kezeld ezeket a hiányzó vagy hibás értékeket megfelelő módon, például kitöltéssel vagy eltávolítással.\n",
    "\n",
    "2. Feature engineering: Vizsgáld meg, hogy az adathalmazban található jellemzők mennyire relevánsak a célváltozóval. Ha szükséges, hozz létre új jellemzőket vagy kombinációkat a meglévő jellemzőkből, amelyek jobban kifejezik a célváltozóval való kapcsolatot.\n",
    "\n",
    "3. Adat normalizálása: Ha az adathalmazban található jellemzők különböző skálákon vannak, fontos lehet normalizálni vagy standardizálni ezeket a jellemzőket. Ez segíthet a modellednek abban, hogy jobban kezelje a különböző skálákon lévő jellemzőket.\n",
    "\n",
    "4. Modellek finomhangolása: Kísérletezz a modellek hiperparamétereivel, például a döntési fák mélységével, a random forestek számával vagy a neurális hálózat rétegeinek számával. Végezz keresztvalidációt vagy grid search-t a legjobb paraméterek megtalálásához.\n",
    "\n",
    "5. Ensemble modellek: Kombinálj több modellt egy ensemble modellben, például a bagging, boosting vagy stacking technikákkal. Ez segíthet a modellednek abban, hogy különböző modellek előnyeit kihasználva jobb pontosságot érjen el.\n",
    "\n",
    "6. Több adat gyűjtése: Ha lehetséges, gyűjts több adatot az adathalmazhoz. Több adat segíthet a modellednek abban, hogy általánosabb és pontosabb eredményeket érjen el.\n",
    "\n",
    "7. Algoritmusváltás: Ha a jelenleg használt modell nem adja meg a kívánt pontosságot, fontolj meg más algoritmusok kipróbálását. Kísérletezz más modellekkel, például SVM, k-NN vagy XGBoost, hogy megtaláld a legjobban illeszkedő modellt az adott problémához.\n",
    "\n",
    "Ezek csak néhány példa a lépésekre, amelyeket megtehetsz a jobb pontosság elérése érdekében. Fontos, hogy kísérletezz és folyamatosan finomítsd a modelledet az adott probléma és adathalmaz alapján."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. feladat\n",
    "### 6.1 feladat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Random keresés segítségével próbálj meg javítani az elért pontosságon.\n",
    "# Jelenítsed meg melyek lettek a legjobb parméterek és mennyivel jobb eredményt sikerült ezekkel elérni.\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the parameter space\n",
    "param_space = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Create a random forest regressor object\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Perform random search\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_space, n_iter=10, cv=5)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
